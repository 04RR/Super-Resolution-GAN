{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SuperResolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "60pm6wapzcu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca62f49-4f8d-479c-b9e5-4f8b88d0eff6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec 18 06:25:23 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    30W /  70W |   3693MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niTK1HcvJ2FO",
        "outputId": "d3a28e6a-b960-4354-b380-717240c6c9ea"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('data')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at data; to attempt to forcibly remount, call drive.mount(\"data\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY5d4R1nb5Rn"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from PIL import Image\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "import torchvision\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import datetime\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torchsummary import summary\r\n",
        "import os\r\n",
        "from torchvision.utils import save_image, make_grid\r\n",
        "\r\n",
        "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2ZwVCigcxJc"
      },
      "source": [
        "transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n",
        "])\r\n",
        "\r\n",
        "class CelebADataset(Dataset):\r\n",
        "    def __init__(self, path, transform, factor, device):\r\n",
        "        self.path = path\r\n",
        "        self.transform = transform\r\n",
        "        self.X = []\r\n",
        "        self.factor = factor\r\n",
        "        for folder in os.listdir(self.path):\r\n",
        "            folder = self.path + folder\r\n",
        "            for img_path in os.listdir(folder):\r\n",
        "                img_path = folder + '/' +  img_path\r\n",
        "                img = np.array(Image.open(img_path))\r\n",
        "                self.X.append(img)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        img = Image.fromarray(self.X[idx])\r\n",
        "        im = Image.fromarray(self.X[idx])\r\n",
        "        imgs_lr = transforms.Resize((37, 37))(img)\r\n",
        "        imgs_lr = self.transform(imgs_lr)\r\n",
        "        im = transforms.Resize((150, 150))(im)\r\n",
        "        imgs_hr = self.transform(im)\r\n",
        "\r\n",
        "        return (imgs_lr.to(device), imgs_hr.to(device))\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_dG9e85cxuX"
      },
      "source": [
        "path = r'/content/data/MyDrive/Intel Image/train/'\r\n",
        "\r\n",
        "if torch.cuda.is_available():\r\n",
        "    device = 'cuda' \r\n",
        "else:\r\n",
        "    device = 'cpu'\r\n",
        "\r\n",
        "dataset = CelebADataset(path, transform, 4, device)\r\n",
        "dataloader = DataLoader(dataset, batch_size= 16, shuffle= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwkWKeTBKtQs",
        "outputId": "bbc53626-2a58-4e43-f8e6-78fcf5551988"
      },
      "source": [
        "dataset[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.8431,  0.8510,  0.8588,  ...,  0.8431,  0.8431,  0.8431],\n",
              "         [ 0.8431,  0.8431,  0.8510,  ...,  0.8667,  0.8588,  0.8588],\n",
              "         [ 0.8275,  0.8275,  0.8275,  ...,  0.8275,  0.8353,  0.8353],\n",
              "         ...,\n",
              "         [-0.9843, -0.8824, -0.8353,  ..., -0.9216, -0.8667, -0.7333],\n",
              "         [-0.9843, -0.9059, -0.8039,  ..., -0.9843, -0.9922, -0.9843],\n",
              "         [-0.9922, -0.9765, -0.9137,  ..., -1.0000, -1.0000, -1.0000]],\n",
              "\n",
              "        [[ 0.7725,  0.7804,  0.7804,  ...,  0.7647,  0.7569,  0.7490],\n",
              "         [ 0.7098,  0.7176,  0.7255,  ...,  0.7333,  0.7255,  0.7176],\n",
              "         [ 0.6157,  0.6235,  0.6314,  ...,  0.6235,  0.6235,  0.6314],\n",
              "         ...,\n",
              "         [-0.9922, -0.8588, -0.7804,  ..., -0.9137, -0.8588, -0.7490],\n",
              "         [-0.9765, -0.9137, -0.8118,  ..., -0.9843, -0.9922, -0.9922],\n",
              "         [-0.9922, -0.9765, -0.9216,  ..., -1.0000, -1.0000, -1.0000]],\n",
              "\n",
              "        [[ 0.6549,  0.6627,  0.6784,  ...,  0.6549,  0.6471,  0.6392],\n",
              "         [ 0.5373,  0.5529,  0.5608,  ...,  0.5608,  0.5608,  0.5529],\n",
              "         [ 0.3647,  0.3725,  0.3882,  ...,  0.3882,  0.3882,  0.3882],\n",
              "         ...,\n",
              "         [-0.9843, -0.8431, -0.7412,  ..., -0.8667, -0.8196, -0.7490],\n",
              "         [-0.9765, -0.8980, -0.7961,  ..., -0.9843, -0.9922, -0.9922],\n",
              "         [-0.9843, -0.9529, -0.9216,  ..., -1.0000, -1.0000, -1.0000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax0_MSDKKtNc",
        "outputId": "99076c28-ca5b-49a4-adfc-67a75b27badf"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8400"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1NaIA6uLFFO",
        "outputId": "830ce57d-c887-45b3-9290-a55117186aca"
      },
      "source": [
        "dataset[0][0].shape, dataset[0][1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 37, 37]), torch.Size([3, 150, 150]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6Tz8NKlaMG"
      },
      "source": [
        "X1, Y1 = [], []\r\n",
        "X2, Y2 = [], []\r\n",
        "\r\n",
        "for item in dataloader:\r\n",
        "    im1, im2 = item\r\n",
        "    _, c1, x1, y1 = im1.shape\r\n",
        "    _, c2, x2, y2 = im2.shape\r\n",
        "    X1.append(x1)\r\n",
        "    X2.append(x2)\r\n",
        "    Y1.append(y1)\r\n",
        "    Y2.append(y2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk_mzuIul7z2",
        "outputId": "579dd5eb-0813-4b49-e57e-470ecac0cd3e"
      },
      "source": [
        "sum(X1)/len(X1), sum(X2)/len(X2), sum(Y1)/len(Y1), sum(Y2)/len(Y2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37.0, 150.0, 37.0, 150.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhkXLJH9cxy_"
      },
      "source": [
        "class FeatureExtractor(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(FeatureExtractor, self).__init__()\r\n",
        "        vgg19_model = torchvision.models.vgg19(pretrained=True)\r\n",
        "        self.feature_extractor = nn.Sequential(*list(vgg19_model.features.children())[:18])\r\n",
        "\r\n",
        "    def forward(self, img):\r\n",
        "        return self.feature_extractor(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXcaU0Sccx10"
      },
      "source": [
        "class ResidualBlock(nn.Module):\r\n",
        "    def __init__(self, in_features):\r\n",
        "        super(ResidualBlock, self).__init__()\r\n",
        "        self.conv_block = nn.Sequential(\r\n",
        "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\r\n",
        "            nn.BatchNorm2d(in_features, 0.8),\r\n",
        "            nn.PReLU(),\r\n",
        "            nn.Conv2d(in_features, in_features, kernel_size=3, stride=1, padding=1),\r\n",
        "            nn.BatchNorm2d(in_features, 0.8),\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        return x + self.conv_block(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRCBY5BKcx5q"
      },
      "source": [
        "class GeneratorResNet(nn.Module):\r\n",
        "    def __init__(self, in_channels=3, out_channels=3, n_residual_blocks=16):\r\n",
        "        super(GeneratorResNet, self).__init__()\r\n",
        "\r\n",
        "        self.conv1 = nn.Sequential(\r\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=9, stride=1, padding=4), \r\n",
        "            nn.PReLU()\r\n",
        "            )\r\n",
        "\r\n",
        "        res_blocks = []\r\n",
        "        for _ in range(n_residual_blocks):\r\n",
        "            res_blocks.append(ResidualBlock(64))\r\n",
        "        self.res_blocks = nn.Sequential(*res_blocks)\r\n",
        "\r\n",
        "        self.conv2 = nn.Sequential(\r\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1), \r\n",
        "            nn.BatchNorm2d(64, 0.8)\r\n",
        "            )\r\n",
        "\r\n",
        "        upsampling = []\r\n",
        "        for out_features in range(2):\r\n",
        "            upsampling += [\r\n",
        "                nn.Conv2d(64, 256, 3, 1, 1),\r\n",
        "                nn.BatchNorm2d(256),\r\n",
        "                nn.PixelShuffle(upscale_factor=2),\r\n",
        "                nn.PReLU(),\r\n",
        "            ]\r\n",
        "        self.upsampling = nn.Sequential(*upsampling)\r\n",
        "\r\n",
        "        self.conv3 = nn.Sequential(\r\n",
        "            nn.Conv2d(64, out_channels, kernel_size=9, stride=1, padding=4), \r\n",
        "            nn.Tanh()\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out1 = self.conv1(x)\r\n",
        "        out = self.res_blocks(out1)\r\n",
        "        out2 = self.conv2(out)\r\n",
        "        out = torch.add(out1, out2)\r\n",
        "        out = self.upsampling(out)\r\n",
        "        out = self.conv3(out)\r\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HEl7DVMcx_Z"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self, input_shape):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "\r\n",
        "        self.input_shape = input_shape\r\n",
        "        in_channels, in_height, in_width = self.input_shape\r\n",
        "        patch_h, patch_w = int(in_height / 2 ** 4), int(in_width / 2 ** 4)\r\n",
        "        self.output_shape = (1, patch_h, patch_w)\r\n",
        "\r\n",
        "        def discriminator_block(in_filters, out_filters, first_block=False):\r\n",
        "            layers = []\r\n",
        "            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\r\n",
        "            if not first_block:\r\n",
        "                layers.append(nn.BatchNorm2d(out_filters))\r\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\r\n",
        "            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\r\n",
        "            layers.append(nn.BatchNorm2d(out_filters))\r\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\r\n",
        "            return layers\r\n",
        "\r\n",
        "        layers = []\r\n",
        "        in_filters = in_channels\r\n",
        "        for i, out_filters in enumerate([64, 128, 256, 512]):\r\n",
        "            layers.extend(discriminator_block(in_filters, out_filters, first_block=(i == 0)))\r\n",
        "            in_filters = out_filters\r\n",
        "        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\r\n",
        "        self.model = nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def forward(self, img):\r\n",
        "        return self.model(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiA96YQHcyDw"
      },
      "source": [
        "feature_ext = FeatureExtractor().float().to(device)\r\n",
        "feature_ext.eval()\r\n",
        "netG = GeneratorResNet().float().to(device)\r\n",
        "netD = Discriminator((3, 150, 150)).float().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9HspbROEXPl",
        "outputId": "7d783d19-d96d-4ac9-c20d-596dcf3eee74"
      },
      "source": [
        "summary(feature_ext, (3, 150, 150))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
            "              ReLU-2         [-1, 64, 150, 150]               0\n",
            "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
            "              ReLU-4         [-1, 64, 150, 150]               0\n",
            "         MaxPool2d-5           [-1, 64, 75, 75]               0\n",
            "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
            "              ReLU-7          [-1, 128, 75, 75]               0\n",
            "            Conv2d-8          [-1, 128, 75, 75]         147,584\n",
            "              ReLU-9          [-1, 128, 75, 75]               0\n",
            "        MaxPool2d-10          [-1, 128, 37, 37]               0\n",
            "           Conv2d-11          [-1, 256, 37, 37]         295,168\n",
            "             ReLU-12          [-1, 256, 37, 37]               0\n",
            "           Conv2d-13          [-1, 256, 37, 37]         590,080\n",
            "             ReLU-14          [-1, 256, 37, 37]               0\n",
            "           Conv2d-15          [-1, 256, 37, 37]         590,080\n",
            "             ReLU-16          [-1, 256, 37, 37]               0\n",
            "           Conv2d-17          [-1, 256, 37, 37]         590,080\n",
            "             ReLU-18          [-1, 256, 37, 37]               0\n",
            "================================================================\n",
            "Total params: 2,325,568\n",
            "Trainable params: 2,325,568\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.26\n",
            "Forward/backward pass size (MB): 91.39\n",
            "Params size (MB): 8.87\n",
            "Estimated Total Size (MB): 100.52\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voWheInZEXVU",
        "outputId": "3c5f6c14-9744-45a9-8a9a-f46ecaace84f"
      },
      "source": [
        "summary(netG, (3, 150, 150))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 150, 150]          15,616\n",
            "             PReLU-2         [-1, 64, 150, 150]               1\n",
            "            Conv2d-3         [-1, 64, 150, 150]          36,928\n",
            "       BatchNorm2d-4         [-1, 64, 150, 150]             128\n",
            "             PReLU-5         [-1, 64, 150, 150]               1\n",
            "            Conv2d-6         [-1, 64, 150, 150]          36,928\n",
            "       BatchNorm2d-7         [-1, 64, 150, 150]             128\n",
            "     ResidualBlock-8         [-1, 64, 150, 150]               0\n",
            "            Conv2d-9         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-10         [-1, 64, 150, 150]             128\n",
            "            PReLU-11         [-1, 64, 150, 150]               1\n",
            "           Conv2d-12         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-13         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-14         [-1, 64, 150, 150]               0\n",
            "           Conv2d-15         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-16         [-1, 64, 150, 150]             128\n",
            "            PReLU-17         [-1, 64, 150, 150]               1\n",
            "           Conv2d-18         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-19         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-20         [-1, 64, 150, 150]               0\n",
            "           Conv2d-21         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-22         [-1, 64, 150, 150]             128\n",
            "            PReLU-23         [-1, 64, 150, 150]               1\n",
            "           Conv2d-24         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-25         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-26         [-1, 64, 150, 150]               0\n",
            "           Conv2d-27         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-28         [-1, 64, 150, 150]             128\n",
            "            PReLU-29         [-1, 64, 150, 150]               1\n",
            "           Conv2d-30         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-31         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-32         [-1, 64, 150, 150]               0\n",
            "           Conv2d-33         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-34         [-1, 64, 150, 150]             128\n",
            "            PReLU-35         [-1, 64, 150, 150]               1\n",
            "           Conv2d-36         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-37         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-38         [-1, 64, 150, 150]               0\n",
            "           Conv2d-39         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-40         [-1, 64, 150, 150]             128\n",
            "            PReLU-41         [-1, 64, 150, 150]               1\n",
            "           Conv2d-42         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-43         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-44         [-1, 64, 150, 150]               0\n",
            "           Conv2d-45         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-46         [-1, 64, 150, 150]             128\n",
            "            PReLU-47         [-1, 64, 150, 150]               1\n",
            "           Conv2d-48         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-49         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-50         [-1, 64, 150, 150]               0\n",
            "           Conv2d-51         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-52         [-1, 64, 150, 150]             128\n",
            "            PReLU-53         [-1, 64, 150, 150]               1\n",
            "           Conv2d-54         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-55         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-56         [-1, 64, 150, 150]               0\n",
            "           Conv2d-57         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-58         [-1, 64, 150, 150]             128\n",
            "            PReLU-59         [-1, 64, 150, 150]               1\n",
            "           Conv2d-60         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-61         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-62         [-1, 64, 150, 150]               0\n",
            "           Conv2d-63         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-64         [-1, 64, 150, 150]             128\n",
            "            PReLU-65         [-1, 64, 150, 150]               1\n",
            "           Conv2d-66         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-67         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-68         [-1, 64, 150, 150]               0\n",
            "           Conv2d-69         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-70         [-1, 64, 150, 150]             128\n",
            "            PReLU-71         [-1, 64, 150, 150]               1\n",
            "           Conv2d-72         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-73         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-74         [-1, 64, 150, 150]               0\n",
            "           Conv2d-75         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-76         [-1, 64, 150, 150]             128\n",
            "            PReLU-77         [-1, 64, 150, 150]               1\n",
            "           Conv2d-78         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-79         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-80         [-1, 64, 150, 150]               0\n",
            "           Conv2d-81         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-82         [-1, 64, 150, 150]             128\n",
            "            PReLU-83         [-1, 64, 150, 150]               1\n",
            "           Conv2d-84         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-85         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-86         [-1, 64, 150, 150]               0\n",
            "           Conv2d-87         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-88         [-1, 64, 150, 150]             128\n",
            "            PReLU-89         [-1, 64, 150, 150]               1\n",
            "           Conv2d-90         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-91         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-92         [-1, 64, 150, 150]               0\n",
            "           Conv2d-93         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-94         [-1, 64, 150, 150]             128\n",
            "            PReLU-95         [-1, 64, 150, 150]               1\n",
            "           Conv2d-96         [-1, 64, 150, 150]          36,928\n",
            "      BatchNorm2d-97         [-1, 64, 150, 150]             128\n",
            "    ResidualBlock-98         [-1, 64, 150, 150]               0\n",
            "           Conv2d-99         [-1, 64, 150, 150]          36,928\n",
            "     BatchNorm2d-100         [-1, 64, 150, 150]             128\n",
            "          Conv2d-101        [-1, 256, 150, 150]         147,712\n",
            "     BatchNorm2d-102        [-1, 256, 150, 150]             512\n",
            "    PixelShuffle-103         [-1, 64, 300, 300]               0\n",
            "           PReLU-104         [-1, 64, 300, 300]               1\n",
            "          Conv2d-105        [-1, 256, 300, 300]         147,712\n",
            "     BatchNorm2d-106        [-1, 256, 300, 300]             512\n",
            "    PixelShuffle-107         [-1, 64, 600, 600]               0\n",
            "           PReLU-108         [-1, 64, 600, 600]               1\n",
            "          Conv2d-109          [-1, 3, 600, 600]          15,555\n",
            "            Tanh-110          [-1, 3, 600, 600]               0\n",
            "================================================================\n",
            "Total params: 1,550,486\n",
            "Trainable params: 1,550,486\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.26\n",
            "Forward/backward pass size (MB): 1994.02\n",
            "Params size (MB): 5.91\n",
            "Estimated Total Size (MB): 2000.19\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pwZ0qpJEXuf",
        "outputId": "bcb9f932-77fd-4885-c269-0c77cf0a21b9"
      },
      "source": [
        "summary(netD, (3, 150, 150))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 150, 150]           1,792\n",
            "         LeakyReLU-2         [-1, 64, 150, 150]               0\n",
            "            Conv2d-3           [-1, 64, 75, 75]          36,928\n",
            "       BatchNorm2d-4           [-1, 64, 75, 75]             128\n",
            "         LeakyReLU-5           [-1, 64, 75, 75]               0\n",
            "            Conv2d-6          [-1, 128, 75, 75]          73,856\n",
            "       BatchNorm2d-7          [-1, 128, 75, 75]             256\n",
            "         LeakyReLU-8          [-1, 128, 75, 75]               0\n",
            "            Conv2d-9          [-1, 128, 38, 38]         147,584\n",
            "      BatchNorm2d-10          [-1, 128, 38, 38]             256\n",
            "        LeakyReLU-11          [-1, 128, 38, 38]               0\n",
            "           Conv2d-12          [-1, 256, 38, 38]         295,168\n",
            "      BatchNorm2d-13          [-1, 256, 38, 38]             512\n",
            "        LeakyReLU-14          [-1, 256, 38, 38]               0\n",
            "           Conv2d-15          [-1, 256, 19, 19]         590,080\n",
            "      BatchNorm2d-16          [-1, 256, 19, 19]             512\n",
            "        LeakyReLU-17          [-1, 256, 19, 19]               0\n",
            "           Conv2d-18          [-1, 512, 19, 19]       1,180,160\n",
            "      BatchNorm2d-19          [-1, 512, 19, 19]           1,024\n",
            "        LeakyReLU-20          [-1, 512, 19, 19]               0\n",
            "           Conv2d-21          [-1, 512, 10, 10]       2,359,808\n",
            "      BatchNorm2d-22          [-1, 512, 10, 10]           1,024\n",
            "        LeakyReLU-23          [-1, 512, 10, 10]               0\n",
            "           Conv2d-24            [-1, 1, 10, 10]           4,609\n",
            "================================================================\n",
            "Total params: 4,693,697\n",
            "Trainable params: 4,693,697\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.26\n",
            "Forward/backward pass size (MB): 66.90\n",
            "Params size (MB): 17.91\n",
            "Estimated Total Size (MB): 85.06\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAE-zoV5iDKE"
      },
      "source": [
        "criterion_GAN = nn.MSELoss()\r\n",
        "criterion_content = nn.L1Loss()\r\n",
        "\r\n",
        "optimizer_G = torch.optim.Adam(netG.parameters(), lr=1e-3)\r\n",
        "optimizer_D = torch.optim.Adam(netD.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6B7L99XEm_y",
        "outputId": "9ef6f2c4-f557-4bc3-9b5c-d1376506581f"
      },
      "source": [
        "epochs = 15\r\n",
        "i=0\r\n",
        "for epoch in range(epochs):\r\n",
        "    for batch in dataloader:\r\n",
        "        imgs_lr, imgs_hr = batch\r\n",
        "\r\n",
        "        valid = torch.tensor(np.ones((imgs_lr.size(0), 10, 10)), dtype=torch.float32).to(device)\r\n",
        "        fake = torch.tensor(np.zeros((imgs_lr.size(0), 10, 10)), dtype=torch.float32).to(device)\r\n",
        "\r\n",
        "        optimizer_G.zero_grad()\r\n",
        "        gen_hr = netG(imgs_lr)\r\n",
        "        loss_GAN = criterion_GAN(netD(gen_hr), valid)\r\n",
        "        gen_features = feature_ext(gen_hr)\r\n",
        "        real_features = feature_ext(imgs_hr)\r\n",
        "        loss_content = criterion_content(gen_features, real_features.detach())\r\n",
        "        loss_G = loss_content + loss_GAN*1e-2\r\n",
        "        loss_G.backward()\r\n",
        "        optimizer_G.step()\r\n",
        "\r\n",
        "        optimizer_D.zero_grad()\r\n",
        "        loss_real = criterion_GAN(netD(imgs_hr), valid)\r\n",
        "        loss_fake = criterion_GAN(netD(gen_hr.detach()), fake)\r\n",
        "        loss_D = loss_real + loss_fake\r\n",
        "\r\n",
        "        loss_D.backward()\r\n",
        "        optimizer_D.step()\r\n",
        "    print(f'{i+1} epochs done')\r\n",
        "    imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\r\n",
        "    gen_hr = make_grid(gen_hr, nrow=1, normalize=True)\r\n",
        "    imgs_lr = make_grid(imgs_lr, nrow=1, normalize=True)\r\n",
        "    img_grid = torch.cat((imgs_lr, gen_hr), -1)\r\n",
        "    save_image(img_grid, f\"/content/data/MyDrive/results/{i+1}.png\", normalize=False)\r\n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([16, 10, 10])) that is different to the input size (torch.Size([16, 1, 10, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1 Epochs done\n",
            "2 Epochs done\n",
            "3 Epochs done\n",
            "4 Epochs done\n",
            "5 Epochs done\n",
            "6 Epochs done\n",
            "7 Epochs done\n",
            "8 Epochs done\n",
            "9 Epochs done\n",
            "10 Epochs done\n",
            "11 Epochs done\n",
            "12 Epochs done\n",
            "13 Epochs done\n",
            "15 Epochs done\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}